{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import numpy as np\n",
    "import dataconfig # run make_config.py to create this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_centers(d, dim):\n",
    "    edges = d.coords[dim].copy()\n",
    "    del d.coords[dim]\n",
    "    d.coords[dim] = 0.5 * (edges[dim, 1:] + edges[dim, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_edges(d, dim):\n",
    "    centers = d.coords[dim].copy()\n",
    "    del d.coords[dim]\n",
    "    first = 1.5*centers[dim, 0] - 0.5*centers[dim, 1]\n",
    "    last = 1.5*centers[dim, -1] - 0.5*centers[dim, -2]\n",
    "    bulk = 0.5 * (centers[dim, 1:] + centers[dim, :-1])\n",
    "    edges = sc.concatenate(first, bulk, dim)\n",
    "    edges = sc.concatenate(edges, last, dim)\n",
    "    d.coords[dim] = edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_bins(data, dim, edges):\n",
    "    data = data.copy()\n",
    "    to_bin_edges(data, dim)\n",
    "    bin_width = data.coords[dim][dim,1:] - data.coords[dim][dim,:-1]\n",
    "    bin_width.unit = sc.units.one\n",
    "    data *= bin_width\n",
    "    data = sc.rebin(data, dim, edges)\n",
    "    bin_width = edges[dim,1:] - edges[dim,:-1]\n",
    "    bin_width.unit = sc.units.one\n",
    "    data /= bin_width\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_by(data, label, coord):\n",
    "    assert len(coord.dims) == 1\n",
    "    out_dim = coord.dims[0]\n",
    "    assert len(data.coords[label].dims) == 1\n",
    "    dim = data.coords[label].dims[0]\n",
    "    out = sc.Variable(dims=coord.dims, shape=coord.shape) * data[dim, 0] \n",
    "    slices = {value:data[dim, index] for index, value in enumerate(data.coords[label].values)}\n",
    "    for i, value in enumerate(coord.values):\n",
    "        out[out_dim, i] = slices[value]\n",
    "    out.coords[label] = coord\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataconfig.data_root\n",
    "direct_beam_file = 'DirectBeam_20feb_full_v3.dat'\n",
    "moderator_file = 'ModeratorStdDev_TS2_SANS_LETexptl_07Aug2015.txt'\n",
    "sample_run_number = 49338\n",
    "sample_transmission_run_number = 49339\n",
    "background_run_number = 49334\n",
    "background_transmission_run_number = 49335\n",
    "\n",
    "def load_larmor(run_number):\n",
    "    return sc.neutron.load(filename=f'{path}/LARMOR000{run_number}.nxs')\n",
    "\n",
    "def load_rkh(filename):\n",
    "    return sc.neutron.load(\n",
    "           filename=filename,\n",
    "           mantid_alg='LoadRKH',\n",
    "           mantid_args={'FirstColumnValue':'Wavelength'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_trans = load_larmor(sample_transmission_run_number)\n",
    "sample = load_larmor(sample_run_number)\n",
    "background_trans = load_larmor(background_transmission_run_number)\n",
    "background = load_larmor(background_run_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtype = sample.coords['position'].dtype\n",
    "sample_pos_offset = sc.Variable(value=[0.0, 0.0, 0.30530], unit=sc.units.m, dtype=dtype)\n",
    "bench_pos_offset = sc.Variable(value=[0.0, 0.001, 0.0], unit=sc.units.m, dtype=dtype)\n",
    "for item in [sample, sample_trans, background, background_trans]:\n",
    "    item.coords['sample_position'] += sample_pos_offset\n",
    "    item.coords['position'] += bench_pos_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wavelength_bins = sc.Variable(\n",
    "    dims=['wavelength'],\n",
    "    unit=sc.units.angstrom,\n",
    "    values=np.geomspace(0.9, 13.5, num=110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_masks(data):\n",
    "    tof = data.coords['tof']\n",
    "    data.masks['bins'] = sc.less(tof['tof',1:], 1500.0 * sc.units.us) | \\\n",
    "                         (sc.greater(tof['tof',:-1], 17500.0 * sc.units.us) & \\\n",
    "                          sc.less(tof['tof',1:], 19000.0 * sc.units.us))\n",
    "    pos = sc.neutron.position(data)\n",
    "    x = sc.geometry.x(pos)\n",
    "    y = sc.geometry.y(pos)\n",
    "    data.masks['beam-stop'] = sc.less(sc.sqrt(x*x+y*y), 0.045 * sc.units.m)\n",
    "    data.masks['tube-ends'] = sc.greater(sc.abs(x), 0.36 * sc.units.m) # roughly all det IDs listed in original\n",
    "    #MaskDetectorsInShape(Workspace=maskWs, ShapeXML=self.maskingPlaneXML) # irrelevant tiny wedge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_mean(data, dim, begin, end):\n",
    "    coord = data.coords[dim]\n",
    "    assert (coord.unit == begin.unit) and (coord.unit == end.unit)\n",
    "    i = np.searchsorted(coord, begin.value)\n",
    "    j = np.searchsorted(coord, end.value) + 1\n",
    "    return data - sc.mean(data[dim, i:j], dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmission_fraction(incident_beam, transmission):\n",
    "    # Approximation based on equations in CalculateTransmission documentation\n",
    "    # TODO proper implementation of mantid.CalculateTransmission\n",
    "    return (transmission / transmission) * (incident_beam / incident_beam)\n",
    "    #CalculateTransmission(SampleRunWorkspace=transWsTmp,\n",
    "    #                      DirectRunWorkspace=transWsTmp,\n",
    "    #                      OutputWorkspace=outWsName,\n",
    "    #                      IncidentBeamMonitor=1,\n",
    "    #                      TransmissionMonitor=4, RebinParams='0.9,-0.025,13.5',\n",
    "    #                      FitMethod='Polynomial',\n",
    "    #                      PolynomialOrder=3, OutputUnfittedData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_monitor_background(data, begin, end):\n",
    "    background = background_mean(data, 'tof', begin, end)\n",
    "    del background.coords['sample_position'] # ensure unit conversion treats this a monitor\n",
    "    background = sc.neutron.convert(background, 'tof', 'wavelength')['spectrum', 0]\n",
    "    background = sc.rebin(background, 'wavelength', wavelength_bins)\n",
    "    return background\n",
    "\n",
    "def setup_transmission(data):\n",
    "    incident_beam = extract_monitor_background(data['spectrum', 0:1], 40000.0*sc.units.us, 99000.0*sc.units.us)\n",
    "    transmission = extract_monitor_background(data['spectrum', 3:4], 88000.0*sc.units.us, 98000.0*sc.units.us)\n",
    "    return transmission_fraction(incident_beam, transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solid_angle(data):\n",
    "    # TODO proper solid angle\n",
    "    # [0.0117188,0.0075,0.0075] bounding box size\n",
    "    pixel_size = 0.0075 * sc.units.m \n",
    "    pixel_length = 0.0117188 * sc.units.m\n",
    "    L2 = sc.neutron.l2(data)\n",
    "    return (pixel_size * pixel_length) / (L2 * L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1d(data, transmission, wavelength_bands=None):\n",
    "    transmission = setup_transmission(transmission)\n",
    "    data = data.copy()\n",
    "    apply_masks(data)\n",
    "    data = sc.neutron.convert(data, 'tof', 'wavelength', out=data)\n",
    "    data = sc.rebin(data, 'wavelength', wavelength_bins)\n",
    "\n",
    "    monitor = data.attrs['monitor1'].value\n",
    "    monitor = background_mean(monitor, 'tof', 40000.0*sc.units.us, 99000.0*sc.units.us)\n",
    "    monitor = sc.neutron.convert(monitor, 'tof', 'wavelength', out=monitor)\n",
    "    monitor = sc.rebin(monitor, 'wavelength', wavelength_bins)\n",
    "\n",
    "    # this factor seems to be a fudge factor. Explanation pending.\n",
    "    data *= 100.0 / 176.71458676442586\n",
    "\n",
    "    # Setup direct beam and normalise to monitor. I.e. adjust for efficiency of detector across the wavelengths.\n",
    "    direct_beam = load_rkh(filename=f'{path}/{direct_beam_file}')\n",
    "    #tmp\n",
    "    for i in range(4):\n",
    "        direct_beam = sc.concatenate(direct_beam, direct_beam, 'layer')\n",
    "    for i in range(10):\n",
    "        db = load_rkh(filename=f'{path}/{direct_beam_file}')# fake loads for timing\n",
    "    direct_beam.coords['layer'] = sc.Variable(dims=['layer'], values=np.arange(16))\n",
    "    layer = sc.Variable(dims=['spectrum'],\n",
    "                        values=np.random.randint(low=0,\n",
    "                                                 high=11,\n",
    "                                                 size=len(data.coords['spectrum'].values)))\n",
    "    direct_beam = broadcast_by(direct_beam, 'layer', layer)\n",
    "    #tmp end\n",
    "    # This would work assuming that there is a least one wavelength point per bin\n",
    "    #direct_beam = sc.groupby(direct_beam, 'wavelength', bins=monitor.coords['wavelength']).mean('wavelength')\n",
    "    direct_beam = map_to_bins(direct_beam, 'wavelength', monitor.coords['wavelength'])\n",
    "    direct_beam = monitor * transmission * direct_beam\n",
    "    \n",
    "    # Estimate qresolution function\n",
    "    moderator = load_rkh(filename=f'{path}/{moderator_file}')\n",
    "    to_bin_edges(moderator, 'wavelength')\n",
    "    # TODO\n",
    "    #qResWs = TOFSANSResolutionByPixel(InputWorkspace=dataWs,\n",
    "    #                                  DeltaR=8,\n",
    "    #                                  SampleApertureRadius=4.0824829046386295,\n",
    "    #                                  SourceApertureRadius=14.433756729740645,\n",
    "    #                                  SigmaModerator=modWs, CollimationLength=5,\n",
    "    #                                  AccountForGravity=True,\n",
    "    #                                  ExtraLength=2)\n",
    "\n",
    "    # TODO temporarily need to manually fix some coord vs. attr\n",
    "    # classification, until scipp unit conversion is handling this better \n",
    "    data.coords['source_position'] = data.attrs['source_position']\n",
    "    data.coords['sample_position'] = data.attrs['sample_position']\n",
    "    data.coords['position'] = data.attrs['position']\n",
    "    #del direct_beam.coords['position']\n",
    "    \n",
    "    q_bins = sc.Variable(\n",
    "        dims=['Q'],\n",
    "        unit=sc.units.one/sc.units.angstrom,\n",
    "        values=np.geomspace(0.008, 0.6, num=55))\n",
    "    # TODO QResolution\n",
    "    d = sc.Dataset({'data':data, 'norm':solid_angle(data)*direct_beam})\n",
    "    to_bin_centers(d, 'wavelength')\n",
    "    d = sc.neutron.convert(d, 'wavelength', 'Q', out=d) # TODO no gravity yet\n",
    "    #d.coords['layer'] = layer\n",
    "    if wavelength_bands is None:\n",
    "        d = sc.histogram(d, q_bins)\n",
    "        #d = sc.sum(d, 'spectrum')\n",
    "        d = sc.groupby(d, 'layer').sum('spectrum')\n",
    "        I = d['data']/d['norm']\n",
    "    else:\n",
    "        # Cut range into number of requested bands\n",
    "        n_band = int(wavelength_bands)\n",
    "        n_bin = len(wavelength_bins.values)-1\n",
    "        bounds = np.arange(n_bin)[::n_bin//n_band]\n",
    "        bounds[-1] = n_bin\n",
    "        slices =  [slice(i, j) for i,j in zip(bounds[:-1],bounds[1:])]\n",
    "        bands = None\n",
    "        # Reduce by wavelength slice\n",
    "        for s in slices:\n",
    "            band = sc.histogram(d['Q', s].copy(), q_bins) # TODO fix scipp to avoid need for copy\n",
    "            #band = sc.sum(band, 'spectrum')\n",
    "            band = sc.groupby(band, 'layer').sum('spectrum')\n",
    "            bands = sc.concatenate(bands, band, 'wavelength') if bands is not None else band\n",
    "        # Add coord for wavelength edges of bands\n",
    "        bands.coords['wavelength'] = sc.Variable(\n",
    "            dims=['wavelength'],\n",
    "            unit=sc.units.angstrom,\n",
    "            values=np.take(wavelength_bins.values, bounds))\n",
    "        I = bands['data']/bands['norm']\n",
    "\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_q1d = q1d(data=sample, transmission=sample_trans, wavelength_bands=None)\n",
    "background_q1d = q1d(data=background, transmission=background_trans, wavelength_bands=None)\n",
    "reduced = sample_q1d - background_q1d\n",
    "\n",
    "reduced.attrs['UserFile'] = sc.Variable(\n",
    "    value='USER_Raspino_191E_BCSLarmor_24Feb2020_v1.txt')\n",
    "reduced.attrs['Transmission'] = sc.Variable(\n",
    "    value=f'{sample_transmission_run_number}_trans_sample_0.9_13.5_unfitted')\n",
    "reduced.attrs['TransmissionCan'] = sc.Variable(\n",
    "    value=f'{background_transmission_run_number}_trans_can_0.9_13.5_unfitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipp.plot import plot\n",
    "values, stddev = np.loadtxt(\"mantid_reduced.txt\")\n",
    "q = np.loadtxt(\"mantid_reduced_q.txt\")\n",
    "\n",
    "mantid = sc.DataArray(data=sc.Variable(['Q'],\n",
    "                                       values=values,\n",
    "                                       variances=stddev*stddev),\n",
    "                      coords={'Q': sc.Variable(['Q'], unit=sc.units.one/sc.units.angstrom, values=q)})\n",
    "mantid = sc.rebin(mantid, 'Q', reduced.coords['Q'])\n",
    "\n",
    "ds = sc.Dataset({'mantid': mantid, 'scipp': reduced})\n",
    "plot(ds, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_q1d = q1d(data=sample, transmission=sample_trans, wavelength_bands=10)\n",
    "background_q1d = q1d(data=background, transmission=background_trans, wavelength_bands=10)\n",
    "reduced = sample_q1d - background_q1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipp.plot import plot\n",
    "plot(reduced['layer',0:4], collapse='Q', logy=True)\n",
    "plot(reduced, log=True, vmin=-2, vmax=np.log(3.0)) # TODO fix https://github.com/scipp/scipp/issues/1112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderator = load_rkh(filename=f'{path}/{moderator_file}')\n",
    "moderator.unit = sc.units.us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tof = moderator.data.copy()\n",
    "tof.variances = None # shortcoming of Mantid or Mantid converter?\n",
    "tof.rename_dims({'wavelength':'tof'}) # TODO overly restrictive check in convert (rename)\n",
    "mod = sc.Dataset(coords={\n",
    "    'tof':tof,\n",
    "    'position':sample.coords['position'],\n",
    "    'source_position':sample.coords['source_position'],\n",
    "    'sample_position':sample.coords['sample_position']})\n",
    "sc.neutron.convert(mod, 'tof', 'wavelength').coords['wavelength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_beam = load_rkh(filename=f'{path}/{direct_beam_file}')\n",
    "direct_beam = sc.concatenate(direct_beam, direct_beam, 'layer')\n",
    "direct_beam.coords['layer'] = sc.Variable(dims=['layer'], values=[0,1])\n",
    "direct_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = sc.Variable(dims=['spectrum'], values=[0,1,0])\n",
    "broadcast_by(direct_beam, 'layer', layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
