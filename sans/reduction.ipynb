{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipp as sc\n",
    "import numpy as np\n",
    "import dataconfig # run make_config.py to create this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpers which still need to be added to scipp, ignore this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_centers(d, dim):\n",
    "    edges = d.coords[dim].copy()\n",
    "    del d.coords[dim]\n",
    "    d.coords[dim] = 0.5 * (edges[dim, 1:] + edges[dim, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_edges(d, dim):\n",
    "    centers = d.coords[dim].copy()\n",
    "    del d.coords[dim]\n",
    "    first = 1.5*centers[dim, 0] - 0.5*centers[dim, 1]\n",
    "    last = 1.5*centers[dim, -1] - 0.5*centers[dim, -2]\n",
    "    bulk = 0.5 * (centers[dim, 1:] + centers[dim, :-1])\n",
    "    edges = sc.concatenate(first, bulk, dim)\n",
    "    edges = sc.concatenate(edges, last, dim)\n",
    "    d.coords[dim] = edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_bins(data, dim, edges):\n",
    "    data = data.copy()\n",
    "    to_bin_edges(data, dim)\n",
    "    bin_width = data.coords[dim][dim,1:] - data.coords[dim][dim,:-1]\n",
    "    bin_width.unit = sc.units.one\n",
    "    data *= bin_width\n",
    "    data = sc.rebin(data, dim, edges)\n",
    "    bin_width = edges[dim,1:] - edges[dim,:-1]\n",
    "    bin_width.unit = sc.units.one\n",
    "    data /= bin_width\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataconfig.data_root\n",
    "direct_beam_file = 'DirectBeam_20feb_full_v3.dat'\n",
    "moderator_file = 'ModeratorStdDev_TS2_SANS_LETexptl_07Aug2015.txt'\n",
    "sample_run_number = 49338\n",
    "sample_transmission_run_number = 49339\n",
    "background_run_number = 49334\n",
    "background_transmission_run_number = 49335\n",
    "\n",
    "def load_larmor(run_number):\n",
    "    return sc.neutron.load(filename=f'{path}/LARMOR000{run_number}.nxs')\n",
    "\n",
    "def load_rkh(filename):\n",
    "    return sc.neutron.load(\n",
    "           filename=filename,\n",
    "           mantid_alg='LoadRKH',\n",
    "           mantid_args={'FirstColumnValue':'Wavelength'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_trans = load_larmor(sample_transmission_run_number)\n",
    "sample = load_larmor(sample_run_number)\n",
    "background_trans = load_larmor(background_transmission_run_number)\n",
    "background = load_larmor(background_run_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtype = sample.coords['position'].dtype\n",
    "sample_pos_offset = sc.Variable(value=[0.0, 0.0, 0.30530], unit=sc.units.m, dtype=dtype)\n",
    "bench_pos_offset = sc.Variable(value=[0.0, 0.001, 0.0], unit=sc.units.m, dtype=dtype)\n",
    "for item in [sample, sample_trans, background, background_trans]:\n",
    "    item.coords['sample-position'] += sample_pos_offset\n",
    "    item.coords['position'] += bench_pos_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wavelength_bins = sc.Variable(\n",
    "    dims=['wavelength'],\n",
    "    unit=sc.units.angstrom,\n",
    "    values=np.geomspace(0.9, 13.5, num=110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_masks(data):\n",
    "    tof = data.coords['tof']\n",
    "    data.masks['bins'] = sc.less(tof['tof',1:], 1500.0 * sc.units.us) | \\\n",
    "                         (sc.greater(tof['tof',:-1], 17500.0 * sc.units.us) & \\\n",
    "                          sc.less(tof['tof',1:], 19000.0 * sc.units.us))\n",
    "    pos = sc.neutron.position(data)\n",
    "    x = sc.geometry.x(pos)\n",
    "    y = sc.geometry.y(pos)\n",
    "    data.masks['beam-stop'] = sc.less(sc.sqrt(x*x+y*y), 0.045 * sc.units.m)\n",
    "    data.masks['tube-ends'] = sc.greater(sc.abs(x), 0.36 * sc.units.m) # roughly all det IDs listed in original\n",
    "    #MaskDetectorsInShape(Workspace=maskWs, ShapeXML=self.maskingPlaneXML) # irrelevant tiny wedge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_mean(data, dim, begin, end):\n",
    "    coord = data.coords[dim]\n",
    "    assert (coord.unit == begin.unit) and (coord.unit == end.unit)\n",
    "    i = np.searchsorted(coord, begin.value)\n",
    "    j = np.searchsorted(coord, end.value) + 1\n",
    "    return data - sc.mean(data[dim, i:j], dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmission_fraction(incident_beam, transmission):\n",
    "    # Approximation based on equations in CalculateTransmission documentation\n",
    "    # TODO proper implementation of mantid.CalculateTransmission\n",
    "    return (transmission / transmission) * (incident_beam / incident_beam)\n",
    "    #CalculateTransmission(SampleRunWorkspace=transWsTmp,\n",
    "    #                      DirectRunWorkspace=transWsTmp,\n",
    "    #                      OutputWorkspace=outWsName,\n",
    "    #                      IncidentBeamMonitor=1,\n",
    "    #                      TransmissionMonitor=4, RebinParams='0.9,-0.025,13.5',\n",
    "    #                      FitMethod='Polynomial',\n",
    "    #                      PolynomialOrder=3, OutputUnfittedData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_monitor_background(data, begin, end):\n",
    "    background = background_mean(data, 'tof', begin, end)\n",
    "    del background.coords['sample-position'] # ensure unit conversion treats this a monitor\n",
    "    background = sc.neutron.convert(background, 'tof', 'wavelength')\n",
    "    background = sc.rebin(background, 'wavelength', wavelength_bins)\n",
    "    return background\n",
    "\n",
    "def setup_transmission(data):\n",
    "    incident_beam = extract_monitor_background(data['spectrum', 0], 40000.0*sc.units.us, 99000.0*sc.units.us)\n",
    "    transmission = extract_monitor_background(data['spectrum', 3], 88000.0*sc.units.us, 98000.0*sc.units.us)\n",
    "    return transmission_fraction(incident_beam, transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solid_angle(data):\n",
    "    # TODO proper solid angle\n",
    "    # [0.0117188,0.0075,0.0075] bounding box size\n",
    "    pixel_size = 0.0075 * sc.units.m \n",
    "    pixel_length = 0.0117188 * sc.units.m\n",
    "    L2 = sc.neutron.l2(data)\n",
    "    return (pixel_size * pixel_length) / (L2 * L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_direct_beam(filenames, layers=None):\n",
    "    \"\"\"Load one or multiple direct beam files, and map to given layers.\n",
    "    \"\"\"\n",
    "    if isinstance(filenames, str):\n",
    "        filenames = [filenames]\n",
    "    dbs = [ load_rkh(filename=f'{path}/{name}') for name in filenames ]\n",
    "    if layers is None and len(dbs) == 1:\n",
    "        return dbs[0]\n",
    "    if layers is None:\n",
    "        raise RuntimeError(\"Got multiple files but no layer mapping\")\n",
    "    direct_beam = None\n",
    "    for db in dbs:\n",
    "        if direct_beam is None:\n",
    "            direct_beam = db\n",
    "        else:\n",
    "            direct_beam = sc.concatenate(direct_beam, db, 'layer')\n",
    "    direct_beam.coords['layer'] = sc.Variable(dims=['layer'], values=np.arange(len(dbs)))\n",
    "    return sc.choose(layer, choices=direct_beam, dim='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_q(data, transmission, direct_beam):\n",
    "    transmission = setup_transmission(transmission)\n",
    "    data = data.copy()\n",
    "    apply_masks(data)\n",
    "    data = sc.neutron.convert(data, 'tof', 'wavelength', out=data)\n",
    "    data = sc.rebin(data, 'wavelength', wavelength_bins)\n",
    "\n",
    "    monitor = data.attrs['monitor1'].value\n",
    "    monitor = background_mean(monitor, 'tof', 40000.0*sc.units.us, 99000.0*sc.units.us)\n",
    "    monitor = sc.neutron.convert(monitor, 'tof', 'wavelength', out=monitor)\n",
    "    monitor = sc.rebin(monitor, 'wavelength', wavelength_bins)\n",
    "\n",
    "    # this factor seems to be a fudge factor. Explanation pending.\n",
    "    data *= 100.0 / 176.71458676442586\n",
    "\n",
    "    # Setup direct beam and normalise to monitor. I.e. adjust for efficiency of detector across the wavelengths.\n",
    "    # This would work assuming that there is a least one wavelength point per bin\n",
    "    #direct_beam = sc.groupby(direct_beam, 'wavelength', bins=monitor.coords['wavelength']).mean('wavelength')\n",
    "    direct_beam = map_to_bins(direct_beam, 'wavelength', monitor.coords['wavelength'])\n",
    "    direct_beam = monitor * transmission * direct_beam\n",
    "    \n",
    "    # Estimate qresolution function\n",
    "    moderator = load_rkh(filename=f'{path}/{moderator_file}')\n",
    "    to_bin_edges(moderator, 'wavelength')\n",
    "    # TODO\n",
    "    #qResWs = TOFSANSResolutionByPixel(InputWorkspace=dataWs,\n",
    "    #                                  DeltaR=8,\n",
    "    #                                  SampleApertureRadius=4.0824829046386295,\n",
    "    #                                  SourceApertureRadius=14.433756729740645,\n",
    "    #                                  SigmaModerator=modWs, CollimationLength=5,\n",
    "    #                                  AccountForGravity=True,\n",
    "    #                                  ExtraLength=2)\n",
    "\n",
    "    # TODO QResolution\n",
    "    d = sc.Dataset({'data':data, 'norm':solid_angle(data)*direct_beam})\n",
    "    to_bin_centers(d, 'wavelength')\n",
    "    return sc.neutron.convert(d, 'wavelength', 'Q', out=d) # TODO no gravity yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(data, q_bins):\n",
    "    data = sc.histogram(data, q_bins)\n",
    "    if 'layer' in data.coords:\n",
    "        return sc.groupby(data, 'layer').sum('spectrum')\n",
    "    else:\n",
    "        return sc.sum(data, 'spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_by_wavelength(data, q_bins, wavelength_bands):\n",
    "    # Cut range into number of requested bands\n",
    "    n_band = int(wavelength_bands)\n",
    "    n_bin = len(wavelength_bins.values)-1\n",
    "    bounds = np.arange(n_bin)[::n_bin//n_band]\n",
    "    bounds[-1] = n_bin\n",
    "    slices =  [slice(i, j) for i,j in zip(bounds[:-1],bounds[1:])]\n",
    "    bands = None\n",
    "    # Reduce by wavelength slice\n",
    "    for s in slices:\n",
    "        band = sc.histogram(data['Q', s], q_bins)\n",
    "        #band = sc.sum(band, 'spectrum')\n",
    "        band = sc.groupby(band, 'layer').sum('spectrum')\n",
    "        bands = sc.concatenate(bands, band, 'wavelength') if bands is not None else band\n",
    "    # Add coord for wavelength edges of bands\n",
    "    bands.coords['wavelength'] = sc.Variable(\n",
    "        dims=['wavelength'],\n",
    "        unit=sc.units.angstrom,\n",
    "        values=np.take(wavelength_bins.values, bounds))\n",
    "    return bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct beam\n",
    "Choose one of the following options (run only one of the two cells) to load the direct beam file:\n",
    "### Option 1: Same for all pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_beam = load_direct_beam(direct_beam_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Different direct beam for different groups of pixels\n",
    "Using randomly assigned IDs for this, change to something appropriate.\n",
    "Filenames should be provided as a list, here we use same for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "layer = sc.Variable(dims=['spectrum'],\n",
    "                    values=np.random.randint(low=0,\n",
    "                                             high=11,\n",
    "                                             size=len(sample.coords['spectrum'].values)))\n",
    "direct_beam = load_direct_beam([direct_beam_file]*11, layers=layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1D\n",
    "\n",
    "### Step 1: Convert to Q\n",
    "Note that this is not `I(Q)` yet.\n",
    "Sum over spectra and normalization happens later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_q = to_q(data=sample, transmission=sample_trans, direct_beam=direct_beam)\n",
    "background_q = to_q(data=background, transmission=background_trans, direct_beam=direct_beam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reduce (sum spectra)\n",
    "Sum spectra. This does take into account potential different layers (see `'layers'` coord).\n",
    "Note that this is still not `I(Q)`, normalization happens later.\n",
    "We have two options, reduce the full wavelength range, or reduce individual wavelength bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_bins = sc.Variable(\n",
    "    dims=['Q'],\n",
    "    unit=sc.units.one/sc.units.angstrom,\n",
    "    values=np.geomspace(0.008, 0.6, num=55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_q_all = reduce(sample_q, q_bins)\n",
    "background_q_all = reduce(background_q, q_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_q_lambda = reduce_by_wavelength(sample_q, q_bins, wavelength_bands=8)\n",
    "background_q_lambda = reduce_by_wavelength(background_q, q_bins, wavelength_bands=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing the latter over `'wavelength'` should give an equivalent result to the full wavelength result, but the former is faster if bands are not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "There are multiple options for this step, depending on whether we need to consider wavelength bands and layers (pixel groups) independently or now.\n",
    "\n",
    "#### Option 1: Combine all layers and normalize\n",
    "This gives just a single `I(Q)` and can be compared to the default output from Mantid's `Q1D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'layer' in sample_q_all.dims:\n",
    "    sample_q1d = sc.sum(sample_q_all, 'layer')\n",
    "    background_q1d = sc.sum(background_q_all, 'layer')\n",
    "else:\n",
    "    sample_q1d = sample_q_all\n",
    "    background_q1d = background_q_all\n",
    "sample_q1d = sample_q1d['data']/sample_q1d['norm']\n",
    "background_q1d = background_q1d['data']/background_q1d['norm']\n",
    "reduced = sample_q1d - background_q1d\n",
    "\n",
    "reduced.attrs['UserFile'] = sc.Variable(\n",
    "    value='USER_Raspino_191E_BCSLarmor_24Feb2020_v1.txt')\n",
    "reduced.attrs['Transmission'] = sc.Variable(\n",
    "    value=f'{sample_transmission_run_number}_trans_sample_0.9_13.5_unfitted')\n",
    "reduced.attrs['TransmissionCan'] = sc.Variable(\n",
    "    value=f'{background_transmission_run_number}_trans_can_0.9_13.5_unfitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipp.plot import plot\n",
    "values, stddev = np.loadtxt(\"mantid_reduced.txt\")\n",
    "q = np.loadtxt(\"mantid_reduced_q.txt\")\n",
    "\n",
    "mantid = sc.DataArray(data=sc.Variable(['Q'],\n",
    "                                       values=values,\n",
    "                                       variances=stddev*stddev),\n",
    "                      coords={'Q': sc.Variable(['Q'], unit=sc.units.one/sc.units.angstrom, values=q)})\n",
    "mantid = sc.rebin(mantid, 'Q', reduced.coords['Q'])\n",
    "\n",
    "ds = sc.Dataset({'mantid': mantid, 'scipp': reduced})\n",
    "plot(ds, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Normalize without combining layers or wavelengths\n",
    "\n",
    "Note that there are multiple options here: We can sum over `'layer'` or sum over `'wavelength'`, or neither.\n",
    "As usualy, summation would need to be done *before* normalization, see option 1.\n",
    "Here we do not perform any sum and obtain `I(wavelength, layer, Q)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q = sample_q_lambda['data']/sample_q_lambda['norm']\n",
    "background_q = background_q_lambda['data']/background_q_lambda['norm']\n",
    "reduced = sample_q - background_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipp.plot import plot\n",
    "plot(reduced['layer',0:4], collapse='Q', logy=True)\n",
    "plot(reduced, log=True, vmin=-2, vmax=np.log(3.0)) # TODO fix https://github.com/scipp/scipp/issues/1112"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
